{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "\n",
    "# Enter data folder name\n",
    "dataset_folder_name = 'roco-dataset'\n",
    "\n",
    "\n",
    "# This dataset_folder structure should look like this:\n",
    "# roco-dataset/\n",
    "#     └── data/\n",
    "#         ├── train/\n",
    "#         │   ├── non-radiology/\n",
    "#         │   │   ├── captions.txt\n",
    "#         │   │   └── images/\n",
    "#         │   └── radiology/\n",
    "#         │       ├── captions.txt\n",
    "#         │       └── images/\n",
    "#         ├── validation/\n",
    "#         │   ├── non-radiology/\n",
    "#         │   │   ├── captions.txt\n",
    "#         │   │   └── images/\n",
    "#         │   └── radiology/\n",
    "#         │       ├── captions.txt\n",
    "#         │       └── images/\n",
    "#         └── test/\n",
    "#             ├── non-radiology/\n",
    "#             │   ├── captions.txt\n",
    "#             │   └── images/\n",
    "#             └── radiology/\n",
    "#                 ├── captions.txt\n",
    "#                 └── images/\n",
    "# \n",
    "# In each \"images\" folder, filenames of images are: \"ROCO_00020.jpg\", \"ROCO_00027.jpg\", etc...\n",
    "# \n",
    "# In \"captions.txt\", the content is stored as below:\n",
    "# ROCO_00020\t Axial computed tomography scan of the pelvis showing a diffuse infiltration of the bladder wall, catheter in situ (arrow).\n",
    "# ROCO_00027\t Postoperative anteroposterior radiograph of the pelvis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The folder '../Experiments/roco-dataset' has been created.\n"
     ]
    }
   ],
   "source": [
    "dataset_dir = '/mnt/eds_ml/Users/Yilu_ML/roco-dataset/data/'\n",
    "\n",
    "# Create a subfolder with the name dataset_folder_name in \"Experiments\" folder, for storing dataset json files.\n",
    "folder_temp = os.path.join('../Experiments', dataset_folder_name)\n",
    "if not os.path.exists(folder_temp):\n",
    "    os.makedirs(folder_temp)\n",
    "    print(f\"The folder '{folder_temp}' has been created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_json_file (dataset_folder_name: str, dataset_dir: str, train_or_val: str):\n",
    "    \"\"\"\n",
    "    Generates a newline-delimited JSON (NDJSON) file containing image paths and corresponding captions.\n",
    "    The function reads from a given 'captions.txt' file and links the captions with image files present in a \n",
    "    specified directory. Non-ASCII captions and those less than 10 characters long are skipped.\n",
    "    The resulting NDJSON file is stored in a specific location defined in the function.\n",
    "\n",
    "    Parameters:\n",
    "    dataset_folder_name (str): Name of the dataset folder, e.g.: 'roco-dataset'\n",
    "    \n",
    "    dataset_dir (str): The base directory containing the dataset folders for training and validation.\n",
    "    \n",
    "    train_or_val (str): A string to specify whether the operation is being performed on 'train' or 'validation' or 'test' data.\n",
    "    This string is used in defining the paths for both reading the 'captions.txt' and image files and writing the output JSON file.\n",
    "\n",
    "    The output JSON file has each line as a separate JSON object of the format:\n",
    "    {\"image_path\": \"<path_to_image>\", \"captions\": [\"<caption_for_image>\"]}\n",
    "\n",
    "    The function does not return any value.\n",
    "    \n",
    "    Note: This function assumes the existence of a 'captions.txt' file and a corresponding 'images' directory \n",
    "    in the specified 'train_or_val' directory.\n",
    "\n",
    "    Raises:\n",
    "    The function continues without raising exceptions but prints the image path if it encounters an invalid image file.\n",
    "    \"\"\"\n",
    "    \n",
    "    json_filepath = os.path.join('../Experiments', dataset_folder_name, f'{train_or_val}_dataset.json')\n",
    "    text_file_path = os.path.join(dataset_dir, train_or_val, 'radiology', 'captions.txt')\n",
    "    image_dir_path = os.path.join(dataset_dir, train_or_val, 'radiology', 'images')\n",
    "\n",
    "    # Open the JSON file for writing\n",
    "    with open(json_filepath, 'w') as json_file:\n",
    "        # Read the captions.txt file\n",
    "        with open(text_file_path, 'r') as file:\n",
    "            for line in file:\n",
    "                # Split the line into the image ID and caption\n",
    "                try:\n",
    "                    image_id, caption = line.strip().split('\\t')\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "                # Processing the caption content\n",
    "                caption = caption.lower().rstrip().replace(\"\\\\n\", \"\").rstrip(\".\")\n",
    "                try:\n",
    "                    # caption = caption.encode('ascii')\n",
    "                    caption = caption.encode('ascii').decode('ascii')\n",
    "                except:\n",
    "                    continue\n",
    "                if len(caption) < 10: #Skip if the caption is too short\n",
    "                    continue\n",
    "\n",
    "                # Construct the path to the image file\n",
    "                image_path = os.path.join(image_dir_path, f'{image_id}.jpg')\n",
    "\n",
    "                # Check if the image file exists\n",
    "                if not os.path.exists(image_path):\n",
    "                    continue\n",
    "                \n",
    "                # to make sure the file is a valid image\n",
    "                try:\n",
    "                    temp_data = torchvision.io.image.read_file(image_path)\n",
    "                except:\n",
    "                    print(image_path)\n",
    "                    continue\n",
    "\n",
    "                # Create the data dictionary\n",
    "                data = {\n",
    "                    'image_path': image_path,\n",
    "                    'captions': [caption]  # wrap caption with a list\n",
    "                }\n",
    "\n",
    "                # Write the data to the JSON file\n",
    "                json_file.write(json.dumps(data) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate json files for train data\n",
    "train_or_val = 'train'\n",
    "generate_json_file(dataset_folder_name, dataset_dir,train_or_val)\n",
    "\n",
    "# Generate json files for validation data\n",
    "train_or_val = 'validation'\n",
    "generate_json_file(dataset_folder_name, dataset_dir,train_or_val)\n",
    "\n",
    "# Generate json files for test data\n",
    "train_or_val = 'test'\n",
    "generate_json_file(dataset_folder_name, dataset_dir,train_or_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available CLIP Models:\n",
      "RN50\n",
      "RN101\n",
      "RN50x4\n",
      "RN50x16\n",
      "RN50x64\n",
      "ViT-B/32\n",
      "ViT-B/16\n",
      "ViT-L/14\n",
      "ViT-L/14@336px\n"
     ]
    }
   ],
   "source": [
    "import clip\n",
    "\n",
    "available_models = clip.available_models()\n",
    "\n",
    "print(\"Available CLIP Models:\")\n",
    "for model in available_models:\n",
    "    print(model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yz_medclip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
